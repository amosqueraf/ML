{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kernel_Keras LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amosqueraf/ML/blob/master/kernel_Keras_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_GUvZpgHWGn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "2e8f070e-6d38-44e2-830a-2e01581dd97e"
      },
      "source": [
        "!echo '{\"username\":\"amosqueraf\",\"key\":\"5c1cd3a8df48572877c8df1fcc57658f\"}' > ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c jigsaw-unintended-bias-in-toxicity-classification -f test.csv -p ../input\n",
        "!kaggle competitions download -c jigsaw-unintended-bias-in-toxicity-classification -f train.csv -p ../input\n",
        "!kaggle competitions download -c jigsaw-unintended-bias-in-toxicity-classification -f sample_submission.csv -p ../input"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading test.csv.zip to ../input\n",
            " 74% 9.00M/12.1M [00:00<00:00, 19.4MB/s]\n",
            "100% 12.1M/12.1M [00:00<00:00, 21.9MB/s]\n",
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading train.csv.zip to ../input\n",
            " 98% 268M/273M [00:01<00:00, 168MB/s]\n",
            "100% 273M/273M [00:01<00:00, 146MB/s]\n",
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading sample_submission.csv.zip to ../input\n",
            "  0% 0.00/221k [00:00<?, ?B/s]\n",
            "100% 221k/221k [00:00<00:00, 61.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvnzLtpBHsIc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6445dc79-c2c4-4e63-f42d-ebbacd3ba5d7"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "import os\n",
        "print(os.listdir(\"../input\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sample_submission.csv.zip', 'train.csv.zip', 'test.csv.zip']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scxzjTXKH-Pt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1c994556-da89-4757-a836-4ddde31efb4d"
      },
      "source": [
        "from keras.preprocessing import text, sequence\n",
        "from keras import backend as K\n",
        "from keras.models import load_model, Sequential\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers.core import Dense, Dropout\n",
        "import keras\n",
        "import pickle\n",
        "from joblib import Parallel, delayed\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "print(K.tensorflow_backend._get_available_gpus())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOuuolADIEV6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "6cc0b40b-fd5c-4509-dca7-7401877ded83"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import SnowballStemmer\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stem = SnowballStemmer('english')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjxAF7FlIFVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv(\"../input/train.csv.zip\")\n",
        "test_df = pd.read_csv(\"../input/test.csv.zip\")\n",
        "\n",
        "train_df = train_df[['id','comment_text', 'target']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4TsR4gfIFYS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "959c35e6-a989-4984-c57f-57122d71363e"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>59848</td>\n",
              "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>59849</td>\n",
              "      <td>Thank you!! This would make my life a lot less...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>59852</td>\n",
              "      <td>This is such an urgent design problem; kudos t...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>59855</td>\n",
              "      <td>Is this something I'll be able to install on m...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>59856</td>\n",
              "      <td>haha you guys are a bunch of losers.</td>\n",
              "      <td>0.893617</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                       comment_text    target\n",
              "0  59848  This is so cool. It's like, 'would you want yo...  0.000000\n",
              "1  59849  Thank you!! This would make my life a lot less...  0.000000\n",
              "2  59852  This is such an urgent design problem; kudos t...  0.000000\n",
              "3  59855  Is this something I'll be able to install on m...  0.000000\n",
              "4  59856               haha you guys are a bunch of losers.  0.893617"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fxahr7_OIFaV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39f2ebea-a30e-487b-9986-2a51eac0472c"
      },
      "source": [
        "train_df.shape, test_df.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1804874, 3), (97320, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn9yMFagIFcq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(text):\n",
        "    \n",
        "    tokens = []\n",
        "    for token in word_tokenize(text):\n",
        "        if token in string.punctuation: continue\n",
        "        if token in stop_words: continue\n",
        "        tokens.append(stem.stem(token))\n",
        "    \n",
        "    return \" \".join(tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6wlnQ4cIFfR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1fb5455a-c961-40b1-8e2c-db37f6f9f575"
      },
      "source": [
        "train_tokens = Parallel(n_jobs=-1, verbose=1)(delayed(tokenize)(text) for text in train_df['comment_text'].tolist())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 5743 tasks      | elapsed:    7.8s\n",
            "[Parallel(n_jobs=-1)]: Done 42343 tasks      | elapsed:   38.4s\n",
            "[Parallel(n_jobs=-1)]: Done 103343 tasks      | elapsed:  1.5min\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9raSDHWAIFj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_tokens = Parallel(n_jobs=-1, verbose=1)(delayed(tokenize)(text) for text in test_df['comment_text'].tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_P0mIgRIFnD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = TfidfVectorizer(stop_words='english')\n",
        "tokenizer.fit(train_tokens + test_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrGKO07XJBc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = train_df[\"comment_text\"]\n",
        "label_data = train_df[\"target\"]\n",
        "test_data = test_df[\"comment_text\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxqMPkNcc_pi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = tokenizer.transform(train_tokens)\n",
        "label_data = train_df[\"target\"]\n",
        "test_data =  tokenizer.transform(test_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwmoCGWu6Qj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data.shape, label_data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiqHQapogy1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_dim = 256\n",
        "lstm_out = 200\n",
        "batch_size = 1000\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(2500, embed_dim,input_length = train_data.shape[1]))\n",
        "model.add(keras.layers.SpatialDropout1D(0.2))\n",
        "model.add(LSTM(lstm_out, dropout=0.25, recurrent_dropout=0.28))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyJoxMP9iEtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(train_data, label_data, batch_size = batch_size, epochs = 1,  verbose = 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkEdc3sMJBwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LSTMModel().model\n",
        "model.fit(\n",
        "    train_data, \n",
        "    label_data, \n",
        "    batch_size = BATCH_SIZE, \n",
        "    epochs = NUM_EPOCH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syJrHFzZJB1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = model.predict(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfieWdaAJB3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submisson_df = pd.read_csv(\"..../input/sample_submission.csv\")\n",
        "submisson_df['prediction'] = result\n",
        "submisson_df['prediction'] = submisson_df['prediction'].apply(lambda x: \"%.5f\" % x if x > 0 else 0.0)\n",
        "submisson_df.to_csv(\"submission.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z99-rhGxJB6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.head()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}